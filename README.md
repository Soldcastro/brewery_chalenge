# brewery_chalenge

## Objetivo

O reposit√≥rio **brewery_chalenge** tem como objetivo central a implementa√ß√£o de um pipeline de dados para ingest√£o, processamento e an√°lise de informa√ß√µes sobre cervejarias, utilizando dados p√∫blicos da Open Brewery DB. O projeto segue uma arquitetura de data lake em camadas (bronze, silver, gold) para organizar os dados e permitir an√°lises mais avan√ßadas.

## Tecnologias Empregadas

- **Python**: Linguagem principal utilizada para codifica√ß√£o dos scripts de ingest√£o e transforma√ß√£o dos dados.
- **Apache Spark**: Usado para processamento distribu√≠do dos dados nas etapas silver e gold, facilitando a manipula√ß√£o de grandes volumes de dados.
- **Apache Airflow**: Utilizado para orquestra√ß√£o dos workflows de dados (conforme evidenciado no Dockerfile da pasta `airflow`).
- **MinIO**: Servi√ßo local de Object Store que utiliza o protocolo do AWS S3.
- **Docker**: Containeriza√ß√£o do ambiente de orquestra√ß√£o com Airflow.
- **Requests (Python)**: Biblioteca utilizada para realizar requisi√ß√µes HTTP √† API da Open Brewery DB.
- **Parquet**: Formato de arquivo utilizado para armazenamento eficiente dos dados processados, principalmente nas camadas silver e gold do data lake.
- **Pytest**: Framework utilizado para testes dos scripts de processamento de dados.

## Estrutura do Pipeline

1. **Ingest√£o (Bronze Layer):**
   - Coleta os dados brutos da API p√∫blica Open Brewery DB utilizando a biblioteca `requests`.
   - Os dados s√£o salvos em arquivos JSON na camada bronze do data lake.

2. **Processamento Silver:**
   - Utiliza Apache Spark para ler os dados brutos (JSON), realizar limpeza, transforma√ß√£o e sele√ß√£o das colunas relevantes.
   - Os dados processados s√£o salvos em formato Parquet, organizados por pa√≠s e tipo de cervejaria.

3. **Agrega√ß√£o Gold:**
   - Novamente com Spark, s√£o realizadas agrega√ß√µes e an√°lises mais complexas sobre os dados transformados.
   - O resultado √© armazenado na camada gold do data lake, pronto para consumo anal√≠tico.

4. **Orquestra√ß√£o:**
   - O Airflow √© utilizado para automatizar e agendar as etapas do pipeline, garantindo a execu√ß√£o ordenada e monitorada dos processos.

## Organiza√ß√£o do Reposit√≥rio

- `notebooks/`: Cont√©m notebooks Jupyter para explora√ß√£o, transforma√ß√£o e an√°lise dos dados nas diferentes camadas do pipeline.
- `spark/scripts/`: Scripts Python para processamento automatizado dos dados.
- `spark/tests/`: Testes automatizados para valida√ß√£o das fun√ß√µes de processamento utilizando Pytest.
- `spark/requirements.txt`: Depend√™ncias Python necess√°rias para execu√ß√£o dos scripts Spark.
- `airflow/`: Dockerfile e configura√ß√µes para ambiente de orquestra√ß√£o com Apache Airflow.
- `minio/`: Script bash de inicializa√ß√£o do MinIO e policy com as permiss√µes de acesso ao bucket.

## Resumo

O **brewery_chalenge** demonstra a aplica√ß√£o de boas pr√°ticas de engenharia de dados, integrando orquestra√ß√£o de workflows, processamento distribu√≠do e testes automatizados para criar um pipeline robusto de ETL (Extract, Transform, Load) voltado para o dom√≠nio de dados de cervejarias.

## D√©bitos T√©cnicos
- Configurar um servidor SMTP ou Webhook no Airflow para alertas de falha na execu√ß√£o da DAG etl_brewery.
- Adicionar o servi√ßo Jupyter a imagem docker para facilitar a explora√ß√£o dos dados e utiliza√ß√£o dos notebooks inclusos.
- Desenvolver um m√≥dulo de Qualidade de Dados (Possivelmente com a biblioteca Great Expectations).
- Adicionar um servi√ßo de DataViz (Possivelmente Metabase).

## üõ† Setup
## Clone o projeto

    $ git clone https://github.com/Soldcastro/brewery_chalenge.git

## Build Docker

    $ cd brewery_chalenge
    $ docker-compose build
    $ docker-compose up -d

## Acesse Airflow UI http://localhost:8090/ com login e senha airflow
## SparkUI dispon√≠vel em http://localhost:8080/
## Spark History Server dispon√≠vel em http://localhost:18080/
## MinIO Object Store dispon√≠vel em http://localhost:9001/ com login e senha minioadmin
## Ative a dag etl_brewery e execute.